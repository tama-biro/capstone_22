{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive modeling notebook\n",
    "\n",
    "This notebook contains the modeling approach using topic distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic distributions and sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from scipy.stats import fisher_exact\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import (GridSearchCV, RandomizedSearchCV,\n",
    "                                     cross_val_predict)\n",
    "from sklearn.svm import SVC\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tsa.stattools import adfuller, kpss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data and setup to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflation = pd.read_csv(\"../dataset/inflation_clean.csv\")\n",
    "unemp = pd.read_csv(\"../dataset/unemp_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflation.rename(columns={\"Unnamed: 0\": \"date\"}, inplace=True)\n",
    "unemp.rename(columns={\"Unnamed: 0\": \"date\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp[\"date\"] = [datetime.strptime(date_str, \"%YM%m\") for date_str in unemp[\"date\"]]\n",
    "inflation[\"date\"] = [\n",
    "    datetime.strptime(date_str, \"%YM%m\") for date_str in inflation[\"date\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_q = pd.read_csv(\"../dataset/topic_q_downsampled.csv\", index_col=\"date\")\n",
    "df_topic_a = pd.read_csv(\"../dataset/topic_a_downsampled.csv\", index_col=\"date\")\n",
    "df_sent = pd.read_csv(\"../dataset/sent_downsampled.csv\", index_col=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent_topic = pd.merge(\n",
    "    df_topic_a.iloc[:, 1:], df_sent[\"answers\"], left_on=\"date\", right_on=\"date\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent_topic = pd.concat(\n",
    "    [df_topic_q.iloc[:, 1:], df_topic_a.iloc[:, 1:], df_sent[[\"questions\", \"answers\"]]],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent_topic.columns = [\n",
    "    \"topic_1_q\",\n",
    "    \"topic_2_q\",\n",
    "    \"topic_3_q\",\n",
    "    \"topic_4_q\",\n",
    "    \"topic_5_q\",\n",
    "    \"topic_1_a\",\n",
    "    \"topic_2_a\",\n",
    "    \"topic_3_a\",\n",
    "    \"topic_4_a\",\n",
    "    \"topic_5_a\",\n",
    "    \"sent_q\",\n",
    "    \"sent_a\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_log_likelihood(w, X, y):\n",
    "    score = np.dot(X, w).reshape(1, X.shape[0])\n",
    "    return np.sum(-np.log(1 + np.exp(score))) + np.sum(y * score)\n",
    "\n",
    "\n",
    "def null_log_likelihood(w, X, y):\n",
    "    z = np.array(\n",
    "        [w if i == 0 else 0.0 for i, w in enumerate(w.reshape(1, X.shape[1])[0])]\n",
    "    ).reshape(X.shape[1], 1)\n",
    "    score = np.dot(X, z).reshape(1, X.shape[0])\n",
    "    return np.sum(-np.log(1 + np.exp(score))) + np.sum(y * score)\n",
    "\n",
    "\n",
    "def mcfadden_rsquare(w, X, y):\n",
    "    return 1.0 - (full_log_likelihood(w, X, y) / null_log_likelihood(w, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented Dickey-Fuller Test (ADF Test)/unit root test\n",
    "def adf_test(ts, signif=0.05):\n",
    "    dftest = adfuller(ts, autolag=\"AIC\")\n",
    "    adf = pd.Series(\n",
    "        dftest[0:4], index=[\"Test Statistic\", \"p-value\", \"# Lags\", \"# Observations\"]\n",
    "    )\n",
    "    for key, value in dftest[4].items():\n",
    "        adf[\"Critical Value (%s)\" % key] = value\n",
    "\n",
    "    p = adf[\"p-value\"]\n",
    "    if p > signif:\n",
    "        print(f\"Series is Non-Stationary\")\n",
    "\n",
    "\n",
    "# KPSS\n",
    "def kpss_test(ts):\n",
    "    kpsstest = kpss(ts, regression=\"c\")\n",
    "    kpss_output = pd.Series(\n",
    "        kpsstest[0:3], index=[\"Test Statistic\", \"p-value\", \"Lags Used\"]\n",
    "    )\n",
    "    if kpss_output[\"p-value\"] > 0.05:\n",
    "        print(\"Stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_pls_cv(X, y, n_comp):\n",
    "    # Define PLS object\n",
    "    pls = PLSRegression(n_components=n_comp)\n",
    "\n",
    "    # Cross-validation\n",
    "    y_cv = cross_val_predict(pls, X, y, cv=10)\n",
    "\n",
    "    # Calculate scores\n",
    "    r2 = r2_score(y, y_cv)\n",
    "    mse = mean_squared_error(y, y_cv)\n",
    "    rpd = y.std() / np.sqrt(mse)\n",
    "\n",
    "    return (y_cv, r2, mse, rpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for unemployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stationarity measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_sent_topic.columns:\n",
    "    print(col)\n",
    "    adf_test(df_sent_topic[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_sent_topic.columns:\n",
    "    print(col)\n",
    "    kpss_test(df_sent_topic[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_sent_topic.columns:\n",
    "    df_sent_topic[col] = df_sent_topic[col] - df_sent_topic[col].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match X and y to have same length and for X to correspond to y in next month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unemp = df_sent_topic[1:-4]\n",
    "y_unemp = unemp[8:-2]\n",
    "y_unemp[\"binary\"] = [1 if x > 0 else 0 for x in y_unemp[\"Delta\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X_unemp.columns\n",
    "vif_data[\"VIF\"] = [\n",
    "    variance_inflation_factor(X_unemp.values, i) for i in range(len(X_unemp.columns))\n",
    "]\n",
    "\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_results = []\n",
    "for n_comp in range(2, len(X_unemp.columns)):\n",
    "    out = optimise_pls_cv(X_unemp, y_unemp[\"binary\"], n_comp=n_comp)\n",
    "    pls_results.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_list = [result[2] for result in pls_results]\n",
    "r2_list = [result[1] for result in pls_results]\n",
    "\n",
    "print(mse_list)\n",
    "r2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_unemp.iloc[:137]\n",
    "X_test = X_unemp.iloc[137:]\n",
    "y_train = y_unemp[\"binary\"].iloc[:137]\n",
    "y_test = y_unemp[\"binary\"].iloc[137:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls = PLSRegression(n_components=2)\n",
    "pls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pls.transform(X_train)\n",
    "X_test = pls.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_mod = LogisticRegression()\n",
    "\n",
    "log_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "grid = {\n",
    "    # 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    \"solver\": [\"newton-cg\"],\n",
    "    \"penalty\": [\"none\", \"l2\"],\n",
    "    \"C\": [100, 10, 1.0, 0.1, 0.01],\n",
    "}\n",
    "\n",
    "clf_unemp = GridSearchCV(log_mod, grid, verbose=1, n_jobs=2)\n",
    "\n",
    "clf_unemp.fit(X_train, y_train)\n",
    "log_mod = clf_unemp.best_estimator_\n",
    "log_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_unemp.predict(X_test)\n",
    "\n",
    "results = classification_report(y_test, y_pred)\n",
    "\n",
    "print(results)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array(log_mod.coef_).transpose()\n",
    "mcfadden_rsquare(w, X_test, y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_mod = SVC()\n",
    "\n",
    "svc_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "# Start with kernel\n",
    "grid = {\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    # \"kernel\": ['poly'],\n",
    "    # 'C': [0.1, 1, 10, 100, 1000],\n",
    "    # 'gamma': [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "}\n",
    "\n",
    "clf_unemp = GridSearchCV(svc_mod, grid, verbose=1, n_jobs=-1)\n",
    "\n",
    "clf_unemp.fit(X_train, y_train)\n",
    "\n",
    "svc_mod = clf_unemp.best_estimator_\n",
    "svc_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_unemp.predict(X_test)\n",
    "\n",
    "results = classification_report(y_test, y_pred)\n",
    "\n",
    "print(results)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits the explainer\n",
    "explainer = shap.Explainer(svc_mod.predict, X_test)\n",
    "# Calculates the SHAP values - It takes some time\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(abs(shap_values.values[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_mod = RandomForestClassifier(random_state=0)\n",
    "\n",
    "rfc_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "grid = {\n",
    "    \"n_estimators\": [int(x) for x in np.linspace(start=50, stop=500, num=10)],\n",
    "    \"max_depth\": [2, 4, 6, 8, 10, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"auto\", \"sqrt\"],\n",
    "    \"bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "clf_unemp = GridSearchCV(rfc_mod, grid, verbose=1, n_jobs=4)\n",
    "\n",
    "clf_unemp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_unemp.predict(X_test)\n",
    "\n",
    "results = classification_report(y_test, y_pred)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(results)\n",
    "\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_mod = xgb.XGBClassifier(\n",
    "    random_state=0,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\",\n",
    "    tree_method=\"gpu_hist\",\n",
    "    verbosity=2,\n",
    ")\n",
    "\n",
    "xgb_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "grid = {\n",
    "    \"eta\": [0.1, 0.2, 0.3],\n",
    "    \"min_child_weight\": [5, 10],\n",
    "    \"gamma\": [0, 1.0, 10],\n",
    "    \"subsample\": np.arange(0.5, 1, 0.1),\n",
    "    \"colsample_bytree\": np.arange(0.5, 1, 0.1),\n",
    "    \"max_depth\": np.arange(3, 10, 2),\n",
    "    \"scale_pos_weight\": [0.5, 1, 2],\n",
    "    \"reg_alpha\": [0, 1, 10.0, 100.0],\n",
    "    \"reg_lambda\": [0, 1, 10.0, 100.0],\n",
    "}\n",
    "\n",
    "# clf_unemp = GridSearchCV(xgb_mod, grid, verbose=2, n_jobs=-1)\n",
    "\n",
    "clf_unemp = RandomizedSearchCV(xgb_mod, grid, verbose=2, n_jobs=-1, n_iter=10000)\n",
    "\n",
    "model = clf_unemp.fit(X_train, y_train)\n",
    "\n",
    "with open(\"../models/xgb_all_unemp.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_unemp.predict(X_test)\n",
    "\n",
    "results = classification_report(y_test, y_pred)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(results)\n",
    "\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unemployment Fisher's exact\n",
    "\n",
    "Below we test whether the accuracy of the model above is beteter during times of high/low volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = log_mod.predict(X_test)\n",
    "y_pred_svc = svc_mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_correct_log = [1 if pred == y_test[i] else 0 for i, pred in enumerate(y_pred_log)]\n",
    "y_correct_svc = [1 if pred == y_test[i] else 0 for i, pred in enumerate(y_pred_svc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volatility = [0] * (59 - 24) + [1] * 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_con = pd.crosstab(y_correct_log, volatility).to_numpy()\n",
    "svc_con = pd.crosstab(y_correct_svc, volatility).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_exact(log_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_exact(svc_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_inflation = df_sent_topic[1:-1]\n",
    "y_inflation = inflation[8:]\n",
    "y_inflation[\"binary\"] = [1 if x > 0 else 0 for x in y_inflation[\"Delta\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X_inflation.columns\n",
    "vif_data[\"VIF\"] = [\n",
    "    variance_inflation_factor(X_inflation.values, i)\n",
    "    for i in range(len(X_inflation.columns))\n",
    "]\n",
    "\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_inflation.iloc[:139, 1:]\n",
    "X_test = X_inflation.iloc[139:, 1:]\n",
    "y_train = y_inflation[\"binary\"].iloc[:139]\n",
    "y_test = y_inflation[\"binary\"].iloc[139:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_results = []\n",
    "for n_comp in range(2, len(X_inflation.columns)):\n",
    "    out = optimise_pls_cv(X_inflation, y_inflation[\"binary\"], n_comp=n_comp)\n",
    "    pls_results.append(out)\n",
    "\n",
    "mse_list = [result[2] for result in pls_results]\n",
    "r2_list = [result[1] for result in pls_results]\n",
    "\n",
    "print(mse_list)\n",
    "r2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls = PLSRegression(n_components=4)\n",
    "pls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pls.transform(X_train)\n",
    "X_test = pls.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_mod = LogisticRegression()\n",
    "\n",
    "log_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "grid = {\n",
    "    # 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    \"solver\": [\"newton-cg\"],\n",
    "    \"penalty\": [\"none\", \"l2\"],\n",
    "    \"C\": [100, 10, 1.0, 0.1, 0.01],\n",
    "}\n",
    "\n",
    "clf_inf = GridSearchCV(log_mod, grid, verbose=1, n_jobs=-1)\n",
    "\n",
    "clf_inf.fit(X_train, y_train)\n",
    "clf_inf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_inf.predict(X_test)\n",
    "\n",
    "results = classification_report(y_test, y_pred)\n",
    "\n",
    "print(results)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_mod = SVC()\n",
    "\n",
    "svc_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "# Start with kernel\n",
    "grid = {\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    # \"kernel\": ['poly'],\n",
    "    # 'C': [0.1, 1, 10, 100, 1000],\n",
    "    # 'gamma': [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "}\n",
    "\n",
    "clf_inf = GridSearchCV(svc_mod, grid, verbose=1, n_jobs=-1)\n",
    "\n",
    "clf_inf.fit(X_train, y_train)\n",
    "clf_inf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_inf.predict(X_test)\n",
    "\n",
    "results = classification_report(y_test, y_pred)\n",
    "\n",
    "print(results)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_mod = RandomForestClassifier(random_state=0)\n",
    "\n",
    "rfc_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "grid = {\n",
    "    \"n_estimators\": [int(x) for x in np.linspace(start=50, stop=500, num=10)],\n",
    "    \"max_depth\": [2, 4, 6, 8, 10, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"auto\", \"sqrt\"],\n",
    "    \"bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "clf_inf = GridSearchCV(rfc_mod, grid, verbose=1, n_jobs=6)\n",
    "\n",
    "clf_inf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_inf.predict(X_test)\n",
    "\n",
    "results = classification_report(y_test, y_pred)\n",
    "\n",
    "print(results)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_mod = xgb.XGBClassifier(\n",
    "    random_state=0,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\",\n",
    "    tree_method=\"gpu_hist\",\n",
    ")\n",
    "\n",
    "xgb_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "grid = {\n",
    "    \"eta\": [0.1, 0.2, 0.3],\n",
    "    \"min_child_weight\": [5, 10],\n",
    "    \"gamma\": [0, 1.0, 10],\n",
    "    \"subsample\": np.arange(0.5, 1, 0.1),\n",
    "    \"colsample_bytree\": np.arange(0.5, 1, 0.1),\n",
    "    \"max_depth\": np.arange(3, 10, 2),\n",
    "    \"scale_pos_weight\": [0.5, 1, 2],\n",
    "    \"reg_alpha\": [0, 1, 10.0, 100.0],\n",
    "    \"reg_lambda\": [0, 1, 10.0, 100.0],\n",
    "}\n",
    "\n",
    "clf_inf = GridSearchCV(xgb_mod, grid, verbose=2, n_jobs=4)\n",
    "\n",
    "# clf_inf = RandomizedSearchCV(xgb_mod, grid, verbose=1, n_jobs=4,\n",
    "#                              random_state=0, n_iter=10000)\n",
    "\n",
    "model = clf_inf.fit(X_train, y_train)\n",
    "\n",
    "# with open('../models/xgb_all_inf.pkl', 'wb') as f:\n",
    "#     pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_inf.predict(X_test)\n",
    "\n",
    "results = classification_report(y_test, y_pred)\n",
    "\n",
    "print(results)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "y_test.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('capstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0c7a101d240af2fba890bd00817b5557287feba80320e30de187c566dd456a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
