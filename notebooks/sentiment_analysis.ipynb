{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_lex = pd.read_csv('../dataset/sensaldo-fullform-v02.txt',\n",
    "                            skiprows=58)\n",
    "df_full = pd.read_csv(\"../dataset/lawline_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean sentiment DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for item in sentiment_lex.values:\n",
    "    row_list = item[0].split('\\t')\n",
    "\n",
    "    word = row_list[0]\n",
    "    sent = row_list[2].split(':')[1]\n",
    "    if len(sent) > 1:\n",
    "        if sent[0] == '-':\n",
    "            sent = sent[:2]\n",
    "        else:\n",
    "            sent = sent[0]\n",
    "    \n",
    "    df_list.append([word, float(sent)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent = pd.DataFrame(df_list, columns=['word', 'sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we make texts lowercase and remove extra whitespaces, newlines, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[\"text_clean\"] = df_full[\"text\"].str.lower()\n",
    "df_full[\"text_clean\"] = [\" \".join(str(item).split()) for item in df_full[\"text_clean\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we remove punctuation, numbers and remove excessive spaces between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_17112\\1199548694.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_full[\"text_clean\"] = df_full[\"text_clean\"].str.replace(\"[^\\w\\s]\", \"\")\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_17112\\1199548694.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_full[\"text_clean\"] = df_full[\"text_clean\"].str.replace(\"[0-9]\", \"\")\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_17112\\1199548694.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_full[\"text_clean\"] = df_full[\"text_clean\"].str.replace(\"\\s{2,}\", \" \")\n"
     ]
    }
   ],
   "source": [
    "df_full[\"text_clean\"] = df_full[\"text_clean\"].str.replace(\"[^\\w\\s]\", \"\")\n",
    "df_full[\"text_clean\"] = df_full[\"text_clean\"].str.replace(\"[0-9]\", \"\")\n",
    "df_full[\"text_clean\"] = df_full[\"text_clean\"].str.replace(\"\\s{2,}\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make each text a list of words. Remove all words not included in sentiment dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_texts = df_full[\"text_clean\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_texts = [[word for word in text.split(' ') if word in df_sent['word'].values.tolist()] for text in list_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_word(word):\n",
    "    idx = df_sent.index[df_sent['word'] == word]\n",
    "    if len(idx) == 1:\n",
    "        sent = df_sent['sentiment'].iloc[idx[0]]\n",
    "        return sent\n",
    "    return np.nan\n",
    "\n",
    "def match_list(text):\n",
    "    temp = list(map(match_word, text))\n",
    "\n",
    "    if len(temp) > 0:\n",
    "        sent_text = np.nanmean(temp)\n",
    "    else:\n",
    "        sent_text = 0\n",
    "\n",
    "    return sent_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_17112\\323735224.py:12: RuntimeWarning: Mean of empty slice\n",
      "  sent_text = np.nanmean(temp)\n"
     ]
    }
   ],
   "source": [
    "sent_list = list(map(match_list, list_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['sentiment'] = sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.to_csv('../dataset/df_with_sent.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('capstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "276a14dae6666bcb6ed89d918896adede68a2b9bdb45438fbd6182b59f67b49f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
