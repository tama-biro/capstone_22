{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling notebook\n",
    "\n",
    "This notebook details the steps taken to clean the data and run topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.stem.snowball import SwedishStemmer\n",
    "import gensim.corpora as corpora\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/lawline_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make new column with lowercase texts and remove all whitespace plus tabs/newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['text'].str.lower()\n",
    "df['text_clean'] = [' '.join(str(item).split()) for item in df['text_clean']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_17600\\1945334599.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text_clean'] = df['text_clean'].str.replace('[^\\w\\s]', '')\n"
     ]
    }
   ],
   "source": [
    "df['text_clean'] = df['text_clean'].str.replace('[^\\w\\s]', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove numbers and replace more than one whitespace with single whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_17600\\1386252719.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text_clean'] = df['text_clean'].str.replace('[0-9]', '')\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_17600\\1386252719.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text_clean'] = df['text_clean'].str.replace('\\s{2,}', ' ')\n"
     ]
    }
   ],
   "source": [
    "df['text_clean'] = df['text_clean'].str.replace('[0-9]', '')\n",
    "df['text_clean'] = df['text_clean'].str.replace('\\s{2,}', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords function\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc))\n",
    "             if word not in stopwords.words('swedish')] for doc in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn texts to list of words and remove stop words. Then turn texts to term document frequency corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn texts to list\n",
    "list_texts = df['text_clean'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almost 1h runtime, keep in mind FUTURE SAM\n",
    "text_words = remove_stopwords(list_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stem words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SwedishStemmer()\n",
    "\n",
    "text_stemmed = [[stemmer.stem(word) for word in doc] for doc in text_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_stemmed = [' '.join(doc) for doc in text_stemmed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=0.15,\n",
    "                     max_df=0.85,\n",
    "                     stop_words=stopwords.words('swedish')) \n",
    "\n",
    "trunc_texts = cv.fit_transform(list_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(text_words)\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in text_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train LDA model on corpus with differing number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_list = []\n",
    "num_topics = [3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 20, 25, 30, 40]\n",
    "\n",
    "# num_topics = [3, 5]\n",
    "\n",
    "for num_topic in num_topics:\n",
    "    mod = LDA(\n",
    "    n_components=num_topic,\n",
    "    max_iter=10,\n",
    "    learning_method='online',\n",
    "    random_state=42,\n",
    "    batch_size=128,\n",
    "    evaluate_every = -1,\n",
    "    n_jobs = -1,\n",
    "    )\n",
    "\n",
    "    lda_output = mod.fit_transform(trunc_texts)\n",
    "\n",
    "    lda_list.append(lda_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\samue\\Documents\\GitHub\\capstone_22\\notebooks\\topic_modeling.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000021?line=0'>1</a>\u001b[0m lda_output \u001b[39m=\u001b[39m lda_list[\u001b[39m8\u001b[39;49m]\u001b[39m.\u001b[39;49mtransform(trunc_texts)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "lda_output = lda_list[8].transform(trunc_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\samue\\Documents\\GitHub\\capstone_22\\notebooks\\topic_modeling.ipynb Cell 2'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000001?line=0'>1</a>\u001b[0m topicnames \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mTopic\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(lda_list[\u001b[39m8\u001b[39m]\u001b[39m.\u001b[39mn_components)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000001?line=1'>2</a>\u001b[0m df_topic_keywords \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(lda_list[\u001b[39m8\u001b[39m]\u001b[39m.\u001b[39mcomponents_)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000001?line=2'>3</a>\u001b[0m df_topic_keywords\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m topicnames\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lda_list' is not defined"
     ]
    }
   ],
   "source": [
    "topicnames = [\"Topic\" + str(i) for i in range(lda_list[8].n_components)]\n",
    "df_topic_keywords = pd.DataFrame(lda_list[8].components_)\n",
    "df_topic_keywords.index = topicnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic0</th>\n",
       "      <td>5871.816794</td>\n",
       "      <td>13542.107684</td>\n",
       "      <td>220.594619</td>\n",
       "      <td>19.643467</td>\n",
       "      <td>0.202560</td>\n",
       "      <td>2713.866676</td>\n",
       "      <td>64624.916144</td>\n",
       "      <td>4.468873</td>\n",
       "      <td>0.201876</td>\n",
       "      <td>0.203849</td>\n",
       "      <td>...</td>\n",
       "      <td>3265.936858</td>\n",
       "      <td>0.204972</td>\n",
       "      <td>0.203498</td>\n",
       "      <td>10161.768328</td>\n",
       "      <td>11699.246787</td>\n",
       "      <td>0.202985</td>\n",
       "      <td>0.202952</td>\n",
       "      <td>0.204174</td>\n",
       "      <td>4648.204633</td>\n",
       "      <td>0.202069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>708.454248</td>\n",
       "      <td>12.386855</td>\n",
       "      <td>3116.771145</td>\n",
       "      <td>2154.724238</td>\n",
       "      <td>0.202525</td>\n",
       "      <td>5644.484185</td>\n",
       "      <td>0.202320</td>\n",
       "      <td>0.203862</td>\n",
       "      <td>0.203026</td>\n",
       "      <td>0.203675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204499</td>\n",
       "      <td>4109.170175</td>\n",
       "      <td>7190.209509</td>\n",
       "      <td>21785.947751</td>\n",
       "      <td>4201.598161</td>\n",
       "      <td>0.202438</td>\n",
       "      <td>0.203081</td>\n",
       "      <td>0.203212</td>\n",
       "      <td>5857.835979</td>\n",
       "      <td>69071.164685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>38713.459305</td>\n",
       "      <td>35898.068099</td>\n",
       "      <td>21283.668229</td>\n",
       "      <td>25749.805481</td>\n",
       "      <td>32136.265248</td>\n",
       "      <td>4555.406223</td>\n",
       "      <td>0.201502</td>\n",
       "      <td>11065.217986</td>\n",
       "      <td>0.203200</td>\n",
       "      <td>24971.194590</td>\n",
       "      <td>...</td>\n",
       "      <td>11073.519400</td>\n",
       "      <td>32901.269576</td>\n",
       "      <td>19757.106105</td>\n",
       "      <td>9308.367518</td>\n",
       "      <td>11375.069580</td>\n",
       "      <td>31998.107610</td>\n",
       "      <td>0.203442</td>\n",
       "      <td>18151.016240</td>\n",
       "      <td>46047.400258</td>\n",
       "      <td>0.202043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>2844.037298</td>\n",
       "      <td>6745.410717</td>\n",
       "      <td>4517.462624</td>\n",
       "      <td>2838.700465</td>\n",
       "      <td>0.202505</td>\n",
       "      <td>11895.662489</td>\n",
       "      <td>0.201756</td>\n",
       "      <td>12261.841313</td>\n",
       "      <td>36801.035477</td>\n",
       "      <td>2858.729635</td>\n",
       "      <td>...</td>\n",
       "      <td>24097.681020</td>\n",
       "      <td>3028.596682</td>\n",
       "      <td>5257.553300</td>\n",
       "      <td>0.211401</td>\n",
       "      <td>47532.637815</td>\n",
       "      <td>0.203085</td>\n",
       "      <td>0.202873</td>\n",
       "      <td>0.203091</td>\n",
       "      <td>12850.682085</td>\n",
       "      <td>0.202142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>18937.636358</td>\n",
       "      <td>3954.529264</td>\n",
       "      <td>3065.453865</td>\n",
       "      <td>3986.311807</td>\n",
       "      <td>0.203946</td>\n",
       "      <td>661.583632</td>\n",
       "      <td>0.202257</td>\n",
       "      <td>2770.731396</td>\n",
       "      <td>0.202631</td>\n",
       "      <td>0.204175</td>\n",
       "      <td>...</td>\n",
       "      <td>2862.152624</td>\n",
       "      <td>22925.617532</td>\n",
       "      <td>0.203366</td>\n",
       "      <td>0.204129</td>\n",
       "      <td>115.516448</td>\n",
       "      <td>20380.072980</td>\n",
       "      <td>25108.848906</td>\n",
       "      <td>3229.011275</td>\n",
       "      <td>6572.790542</td>\n",
       "      <td>0.201624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4   \\\n",
       "Topic0   5871.816794  13542.107684    220.594619     19.643467      0.202560   \n",
       "Topic1    708.454248     12.386855   3116.771145   2154.724238      0.202525   \n",
       "Topic2  38713.459305  35898.068099  21283.668229  25749.805481  32136.265248   \n",
       "Topic3   2844.037298   6745.410717   4517.462624   2838.700465      0.202505   \n",
       "Topic4  18937.636358   3954.529264   3065.453865   3986.311807      0.203946   \n",
       "\n",
       "                  5             6             7             8             9   \\\n",
       "Topic0   2713.866676  64624.916144      4.468873      0.201876      0.203849   \n",
       "Topic1   5644.484185      0.202320      0.203862      0.203026      0.203675   \n",
       "Topic2   4555.406223      0.201502  11065.217986      0.203200  24971.194590   \n",
       "Topic3  11895.662489      0.201756  12261.841313  36801.035477   2858.729635   \n",
       "Topic4    661.583632      0.202257   2770.731396      0.202631      0.204175   \n",
       "\n",
       "        ...            55            56            57            58  \\\n",
       "Topic0  ...   3265.936858      0.204972      0.203498  10161.768328   \n",
       "Topic1  ...      0.204499   4109.170175   7190.209509  21785.947751   \n",
       "Topic2  ...  11073.519400  32901.269576  19757.106105   9308.367518   \n",
       "Topic3  ...  24097.681020   3028.596682   5257.553300      0.211401   \n",
       "Topic4  ...   2862.152624  22925.617532      0.203366      0.204129   \n",
       "\n",
       "                  59            60            61            62            63  \\\n",
       "Topic0  11699.246787      0.202985      0.202952      0.204174   4648.204633   \n",
       "Topic1   4201.598161      0.202438      0.203081      0.203212   5857.835979   \n",
       "Topic2  11375.069580  31998.107610      0.203442  18151.016240  46047.400258   \n",
       "Topic3  47532.637815      0.203085      0.202873      0.203091  12850.682085   \n",
       "Topic4    115.516448  20380.072980  25108.848906   3229.011275   6572.790542   \n",
       "\n",
       "                  64  \n",
       "Topic0      0.202069  \n",
       "Topic1  69071.164685  \n",
       "Topic2      0.202043  \n",
       "Topic3      0.202142  \n",
       "Topic4      0.201624  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_topics(vectorizer, lda_model, n_words=20):\n",
    "    keywords = np.array(vectorizer.get_feature_names_out())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords\n",
    "\n",
    "topic_keywords = show_topics(vectorizer=cv, lda_model=lda_list[1], n_words=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Word 10</th>\n",
       "      <th>Word 11</th>\n",
       "      <th>Word 12</th>\n",
       "      <th>Word 13</th>\n",
       "      <th>Word 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>rätt</td>\n",
       "      <td>barn</td>\n",
       "      <td>få</td>\n",
       "      <td>del</td>\n",
       "      <td>får</td>\n",
       "      <td>finns</td>\n",
       "      <td>andra</td>\n",
       "      <td>går</td>\n",
       "      <td>kommer</td>\n",
       "      <td>vill</td>\n",
       "      <td>två</td>\n",
       "      <td>första</td>\n",
       "      <td>alltså</td>\n",
       "      <td>ska</td>\n",
       "      <td>eftersom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>år</td>\n",
       "      <td>hej</td>\n",
       "      <td>två</td>\n",
       "      <td>gäller</td>\n",
       "      <td>fick</td>\n",
       "      <td>står</td>\n",
       "      <td>fråga</td>\n",
       "      <td>fått</td>\n",
       "      <td>finns</td>\n",
       "      <td>innan</td>\n",
       "      <td>får</td>\n",
       "      <td>tid</td>\n",
       "      <td>svar</td>\n",
       "      <td>samt</td>\n",
       "      <td>även</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>ska</td>\n",
       "      <td>enligt</td>\n",
       "      <td>kap</td>\n",
       "      <td>fall</td>\n",
       "      <td>finns</td>\n",
       "      <td>fråga</td>\n",
       "      <td>dock</td>\n",
       "      <td>se</td>\n",
       "      <td>gäller</td>\n",
       "      <td>även</td>\n",
       "      <td>får</td>\n",
       "      <td>måste</td>\n",
       "      <td>alltså</td>\n",
       "      <td>innebär</td>\n",
       "      <td>andra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>ska</td>\n",
       "      <td>vill</td>\n",
       "      <td>in</td>\n",
       "      <td>betala</td>\n",
       "      <td>göra</td>\n",
       "      <td>kommer</td>\n",
       "      <td>få</td>\n",
       "      <td>hej</td>\n",
       "      <td>ta</td>\n",
       "      <td>får</td>\n",
       "      <td>måste</td>\n",
       "      <td>hos</td>\n",
       "      <td>gå</td>\n",
       "      <td>går</td>\n",
       "      <td>gör</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>kap</td>\n",
       "      <td>egendom</td>\n",
       "      <td>ska</td>\n",
       "      <td>fråga</td>\n",
       "      <td>vänlig</td>\n",
       "      <td>hälsning</td>\n",
       "      <td>kommer</td>\n",
       "      <td>lawline</td>\n",
       "      <td>hej</td>\n",
       "      <td>tack</td>\n",
       "      <td>enligt</td>\n",
       "      <td>genom</td>\n",
       "      <td>vänder</td>\n",
       "      <td>svar</td>\n",
       "      <td>innebär</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word 0   Word 1 Word 2  Word 3  Word 4    Word 5  Word 6   Word 7  \\\n",
       "Topic 0   rätt     barn     få     del     får     finns   andra      går   \n",
       "Topic 1     år      hej    två  gäller    fick      står   fråga     fått   \n",
       "Topic 2    ska   enligt    kap    fall   finns     fråga    dock       se   \n",
       "Topic 3    ska     vill     in  betala    göra    kommer      få      hej   \n",
       "Topic 4    kap  egendom    ska   fråga  vänlig  hälsning  kommer  lawline   \n",
       "\n",
       "         Word 8 Word 9 Word 10 Word 11 Word 12  Word 13   Word 14  \n",
       "Topic 0  kommer   vill     två  första  alltså      ska  eftersom  \n",
       "Topic 1   finns  innan     får     tid    svar     samt      även  \n",
       "Topic 2  gäller   även     får   måste  alltså  innebär     andra  \n",
       "Topic 3      ta    får   måste     hos      gå      går       gör  \n",
       "Topic 4     hej   tack  enligt   genom  vänder     svar   innebär  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Topic0', 'Topic1', 'Topic2', 'Topic3']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_list = []\n",
    "num_topics = [3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 20, 25, 30, 40]\n",
    "\n",
    "for num_topic in num_topics:\n",
    "    mod = LdaMulticore(corpus=corpus, id2word=id2word, num_topics=num_topic)\n",
    "    lda_list.append(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.018*\"ska\" + 0.013*\"kap\" + 0.008*\"finns\" + 0.008*\"fråga\" + 0.007*\"rätt\" + 0.006*\"kommer\" + 0.006*\"vänder\" + 0.006*\"få\" + 0.005*\"även\" + 0.005*\"tack\"')\n",
      "(1, '0.018*\"ska\" + 0.011*\"kap\" + 0.009*\"fråga\" + 0.008*\"finns\" + 0.007*\"rätt\" + 0.006*\"får\" + 0.006*\"hej\" + 0.006*\"svar\" + 0.005*\"år\" + 0.005*\"enligt\"')\n",
      "(2, '0.017*\"ska\" + 0.010*\"kap\" + 0.009*\"kommer\" + 0.009*\"fråga\" + 0.009*\"rätt\" + 0.008*\"egendom\" + 0.008*\"finns\" + 0.008*\"får\" + 0.008*\"få\" + 0.007*\"barn\"')\n",
      "(3, '0.015*\"ska\" + 0.009*\"får\" + 0.008*\"kap\" + 0.008*\"rätt\" + 0.007*\"fråga\" + 0.006*\"finns\" + 0.005*\"hej\" + 0.005*\"lawline\" + 0.005*\"innebär\" + 0.005*\"fel\"')\n",
      "(4, '0.012*\"ska\" + 0.010*\"kap\" + 0.008*\"finns\" + 0.007*\"får\" + 0.007*\"fråga\" + 0.006*\"rätt\" + 0.005*\"kommer\" + 0.005*\"lawline\" + 0.005*\"hej\" + 0.005*\"även\"')\n",
      "(5, '0.017*\"ska\" + 0.009*\"kap\" + 0.008*\"fråga\" + 0.007*\"rätt\" + 0.006*\"finns\" + 0.006*\"lawline\" + 0.006*\"vill\" + 0.005*\"enligt\" + 0.005*\"fall\" + 0.005*\"avtalet\"')\n",
      "(6, '0.010*\"ska\" + 0.008*\"kommer\" + 0.008*\"fråga\" + 0.006*\"kap\" + 0.005*\"hej\" + 0.005*\"få\" + 0.005*\"får\" + 0.005*\"fall\" + 0.005*\"andra\" + 0.004*\"finns\"')\n",
      "(7, '0.018*\"ska\" + 0.010*\"kap\" + 0.009*\"år\" + 0.007*\"fråga\" + 0.006*\"vill\" + 0.006*\"hej\" + 0.006*\"huset\" + 0.006*\"barn\" + 0.005*\"kommer\" + 0.005*\"får\"')\n",
      "(8, '0.012*\"ska\" + 0.009*\"kap\" + 0.009*\"fråga\" + 0.007*\"får\" + 0.006*\"även\" + 0.005*\"kommer\" + 0.005*\"lawline\" + 0.005*\"hej\" + 0.005*\"andra\" + 0.005*\"gäller\"')\n",
      "(9, '0.012*\"ska\" + 0.007*\"kommer\" + 0.007*\"finns\" + 0.006*\"får\" + 0.006*\"kap\" + 0.006*\"hej\" + 0.006*\"gäller\" + 0.006*\"även\" + 0.006*\"rätt\" + 0.006*\"fråga\"')\n"
     ]
    }
   ],
   "source": [
    "mod_viz = lda_list[7]\n",
    "\n",
    "topics = mod_viz.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('capstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "276a14dae6666bcb6ed89d918896adede68a2b9bdb45438fbd6182b59f67b49f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
