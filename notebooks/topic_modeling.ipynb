{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling notebook\n",
    "\n",
    "This notebook details the steps taken to clean the data and run topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SwedishStemmer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\"../dataset/lawline_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make new column with lowercase texts and remove all whitespace plus tabs/newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only questions/answers\n",
    "df = df_full.iloc[::2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_18072\\1881496573.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text_clean'] = df['text'].str.lower()\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_18072\\1881496573.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text_clean'] = [' '.join(str(item).split()) for item in df['text_clean']]\n"
     ]
    }
   ],
   "source": [
    "df[\"text_clean\"] = df[\"text\"].str.lower()\n",
    "df[\"text_clean\"] = [\" \".join(str(item).split()) for item in df[\"text_clean\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_18072\\1945334599.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text_clean'] = df['text_clean'].str.replace('[^\\w\\s]', '')\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_18072\\1945334599.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text_clean'] = df['text_clean'].str.replace('[^\\w\\s]', '')\n"
     ]
    }
   ],
   "source": [
    "df[\"text_clean\"] = df[\"text_clean\"].str.replace(\"[^\\w\\s]\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove numbers and replace more than one whitespace with single whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_18072\\1386252719.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text_clean'] = df['text_clean'].str.replace('[0-9]', '')\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_18072\\1386252719.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text_clean'] = df['text_clean'].str.replace('[0-9]', '')\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_18072\\1386252719.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text_clean'] = df['text_clean'].str.replace('\\s{2,}', ' ')\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_18072\\1386252719.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text_clean'] = df['text_clean'].str.replace('\\s{2,}', ' ')\n"
     ]
    }
   ],
   "source": [
    "df[\"text_clean\"] = df[\"text_clean\"].str.replace(\"[0-9]\", \"\")\n",
    "df[\"text_clean\"] = df[\"text_clean\"].str.replace(\"\\s{2,}\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords function\n",
    "def remove_stopwords(texts, stop_words):\n",
    "    return [\n",
    "        [word for word in simple_preprocess(str(doc)) if word not in stop_words]\n",
    "        for doc in texts\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn texts to list of words and remove stop words. Then turn texts to term document frequency corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn texts to list\n",
    "list_texts = df[\"text_clean\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"swedish\")\n",
    "stop_words.extend([\"hej\", \"ska\", \"in\", \"vill\", \"alltså\", \"lawline\", \"även\"])\n",
    "\n",
    "text_words = remove_stopwords(list_texts, stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stem words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SwedishStemmer()\n",
    "\n",
    "text_stemmed = [[stemmer.stem(word) for word in doc] for doc in text_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_stemmed = [\" \".join(doc) for doc in text_stemmed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=0.15, max_df=0.85, stop_words=stopwords.words(\"swedish\"))\n",
    "\n",
    "trunc_texts = cv.fit_transform(docs_stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train LDA model on corpus with differing number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\samue\\Documents\\GitHub\\capstone_22\\notebooks\\topic_modeling.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000019?line=12'>13</a>\u001b[0m \u001b[39m# clf = RandomizedSearchCV(mod, param_distributions=grid, n_jobs=-1,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000019?line=13'>14</a>\u001b[0m \u001b[39m#                          n_iter=10, verbose=1)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000019?line=15'>16</a>\u001b[0m clf \u001b[39m=\u001b[39m GridSearchCV(mod, param_grid\u001b[39m=\u001b[39mgrid, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000019?line=17'>18</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(trunc_texts)\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1374\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1375\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n\u001b[0;32m    825\u001b[0m         X,\n\u001b[0;32m    826\u001b[0m         y,\n\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    837\u001b[0m )\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\concurrent\\futures\\_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 440\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    443\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# First take Grid Search approach\n",
    "grid = {\n",
    "    #'doc_topic_prior': [.05, .1, .5, 1, 5, 10],\n",
    "    #'topic_word_prior': [.05, .1, .5, 1, 5, 10],\n",
    "    \"n_components\": [3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 20],\n",
    "    #'learning_decay': [.5, .7, 1]\n",
    "}\n",
    "\n",
    "mod = LDA(\n",
    "    max_iter=10,\n",
    "    learning_method=\"online\",\n",
    "    random_state=42,\n",
    "    batch_size=128,\n",
    "    evaluate_every=-1,\n",
    ")\n",
    "\n",
    "# clf = RandomizedSearchCV(mod, param_distributions=grid, n_jobs=-1,\n",
    "#                          n_iter=10, verbose=1)\n",
    "\n",
    "clf = GridSearchCV(mod, param_grid=grid, n_jobs=-1, verbose=1)\n",
    "\n",
    "clf.fit(trunc_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\samue\\Documents\\GitHub\\capstone_22\\notebooks\\topic_modeling.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000020?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m num_topic \u001b[39min\u001b[39;00m num_topics:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000020?line=4'>5</a>\u001b[0m     mod \u001b[39m=\u001b[39m LDA(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000020?line=5'>6</a>\u001b[0m     n_components\u001b[39m=\u001b[39mnum_topic,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000020?line=6'>7</a>\u001b[0m     max_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000020?line=11'>12</a>\u001b[0m     n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000020?line=12'>13</a>\u001b[0m     )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000020?line=14'>15</a>\u001b[0m     mod\u001b[39m.\u001b[39;49mfit(trunc_texts)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000020?line=16'>17</a>\u001b[0m     lda_list\u001b[39m.\u001b[39mappend(mod)\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:632\u001b[0m, in \u001b[0;36mLatentDirichletAllocation.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m learning_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39monline\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    631\u001b[0m     \u001b[39mfor\u001b[39;00m idx_slice \u001b[39min\u001b[39;00m gen_batches(n_samples, batch_size):\n\u001b[1;32m--> 632\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_em_step(\n\u001b[0;32m    633\u001b[0m             X[idx_slice, :],\n\u001b[0;32m    634\u001b[0m             total_samples\u001b[39m=\u001b[39;49mn_samples,\n\u001b[0;32m    635\u001b[0m             batch_update\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    636\u001b[0m             parallel\u001b[39m=\u001b[39;49mparallel,\n\u001b[0;32m    637\u001b[0m         )\n\u001b[0;32m    638\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     \u001b[39m# batch update\u001b[39;00m\n\u001b[0;32m    640\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_em_step(\n\u001b[0;32m    641\u001b[0m         X, total_samples\u001b[39m=\u001b[39mn_samples, batch_update\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, parallel\u001b[39m=\u001b[39mparallel\n\u001b[0;32m    642\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:503\u001b[0m, in \u001b[0;36mLatentDirichletAllocation._em_step\u001b[1;34m(self, X, total_samples, batch_update, parallel)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[39m\"\"\"EM update for 1 iteration.\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \n\u001b[0;32m    478\u001b[0m \u001b[39mupdate `_component` by batch VB or online VB.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[39m    Unnormalized document topic distribution.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[39m# E-step\u001b[39;00m\n\u001b[1;32m--> 503\u001b[0m _, suff_stats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_e_step(\n\u001b[0;32m    504\u001b[0m     X, cal_sstats\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, random_init\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, parallel\u001b[39m=\u001b[39;49mparallel\n\u001b[0;32m    505\u001b[0m )\n\u001b[0;32m    507\u001b[0m \u001b[39m# M-step\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[39mif\u001b[39;00m batch_update:\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:446\u001b[0m, in \u001b[0;36mLatentDirichletAllocation._e_step\u001b[1;34m(self, X, cal_sstats, random_init, parallel)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[39mif\u001b[39;00m parallel \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[1;32m--> 446\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    447\u001b[0m     delayed(_update_doc_distribution)(\n\u001b[0;32m    448\u001b[0m         X[idx_slice, :],\n\u001b[0;32m    449\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexp_dirichlet_component_,\n\u001b[0;32m    450\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdoc_topic_prior_,\n\u001b[0;32m    451\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_doc_update_iter,\n\u001b[0;32m    452\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean_change_tol,\n\u001b[0;32m    453\u001b[0m         cal_sstats,\n\u001b[0;32m    454\u001b[0m         random_state,\n\u001b[0;32m    455\u001b[0m     )\n\u001b[0;32m    456\u001b[0m     \u001b[39mfor\u001b[39;49;00m idx_slice \u001b[39min\u001b[39;49;00m gen_even_slices(X\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], n_jobs)\n\u001b[0;32m    457\u001b[0m )\n\u001b[0;32m    459\u001b[0m \u001b[39m# merge result\u001b[39;00m\n\u001b[0;32m    460\u001b[0m doc_topics, sstats_list \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mresults)\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\concurrent\\futures\\_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 440\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    443\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lda_list = []\n",
    "num_topics = [3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 20]\n",
    "\n",
    "for num_topic in num_topics:\n",
    "    mod = LDA(\n",
    "        n_components=num_topic,\n",
    "        max_iter=10,\n",
    "        learning_method=\"online\",\n",
    "        random_state=42,\n",
    "        batch_size=128,\n",
    "        evaluate_every=-1,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    mod.fit(trunc_texts)\n",
    "\n",
    "    lda_list.append(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perp_list = [mod.perplexity(trunc_texts) for mod in lda_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lda_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25756578, 0.06250098, 0.23794881, ..., 0.1274021 , 0.06429844,\n",
       "        0.12503265],\n",
       "       [0.02619643, 0.11613501, 0.04569761, ..., 0.10614123, 0.12610509,\n",
       "        0.35032662],\n",
       "       [0.06019153, 0.05267255, 0.36153796, ..., 0.15968172, 0.0563115 ,\n",
       "        0.10621732],\n",
       "       ...,\n",
       "       [0.03644769, 0.20400431, 0.07238093, ..., 0.34555503, 0.06999842,\n",
       "        0.08215634],\n",
       "       [0.10021088, 0.20131982, 0.10002629, ..., 0.10033306, 0.195307  ,\n",
       "        0.10034966],\n",
       "       [0.07692671, 0.08426497, 0.07692308, ..., 0.17045307, 0.22731104,\n",
       "        0.08578097]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_transform(trunc_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicnames = [\"Topic\" + str(i) for i in range(model.n_components)]\n",
    "df_topic_keywords = pd.DataFrame(model.components_)\n",
    "df_topic_keywords.index = topicnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic0</th>\n",
       "      <td>154.187145</td>\n",
       "      <td>1.510541</td>\n",
       "      <td>0.100016</td>\n",
       "      <td>11.215323</td>\n",
       "      <td>0.100017</td>\n",
       "      <td>0.100019</td>\n",
       "      <td>19.361503</td>\n",
       "      <td>590.095924</td>\n",
       "      <td>0.100022</td>\n",
       "      <td>5.318551</td>\n",
       "      <td>...</td>\n",
       "      <td>3.327713</td>\n",
       "      <td>0.100021</td>\n",
       "      <td>30.095829</td>\n",
       "      <td>66158.557600</td>\n",
       "      <td>40855.950700</td>\n",
       "      <td>0.449685</td>\n",
       "      <td>2.557207</td>\n",
       "      <td>0.228810</td>\n",
       "      <td>15159.559355</td>\n",
       "      <td>69071.072458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>10224.871870</td>\n",
       "      <td>983.917846</td>\n",
       "      <td>0.100010</td>\n",
       "      <td>822.665069</td>\n",
       "      <td>0.100016</td>\n",
       "      <td>0.100017</td>\n",
       "      <td>37458.633086</td>\n",
       "      <td>5179.528547</td>\n",
       "      <td>0.750411</td>\n",
       "      <td>72425.579740</td>\n",
       "      <td>...</td>\n",
       "      <td>328.957354</td>\n",
       "      <td>0.100021</td>\n",
       "      <td>367.533959</td>\n",
       "      <td>0.103667</td>\n",
       "      <td>0.100020</td>\n",
       "      <td>0.100019</td>\n",
       "      <td>30.563796</td>\n",
       "      <td>314.032476</td>\n",
       "      <td>29058.007533</td>\n",
       "      <td>0.100014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>61.804112</td>\n",
       "      <td>0.424129</td>\n",
       "      <td>0.100013</td>\n",
       "      <td>35211.559621</td>\n",
       "      <td>60797.470774</td>\n",
       "      <td>0.100019</td>\n",
       "      <td>10.506632</td>\n",
       "      <td>268.111232</td>\n",
       "      <td>0.100020</td>\n",
       "      <td>0.108266</td>\n",
       "      <td>...</td>\n",
       "      <td>56446.297680</td>\n",
       "      <td>41283.548772</td>\n",
       "      <td>20.037134</td>\n",
       "      <td>0.100052</td>\n",
       "      <td>0.100020</td>\n",
       "      <td>80919.916001</td>\n",
       "      <td>0.104183</td>\n",
       "      <td>0.289335</td>\n",
       "      <td>1906.759769</td>\n",
       "      <td>0.100016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>15359.187962</td>\n",
       "      <td>6783.401664</td>\n",
       "      <td>0.100014</td>\n",
       "      <td>726.276421</td>\n",
       "      <td>0.100015</td>\n",
       "      <td>0.100020</td>\n",
       "      <td>7340.134007</td>\n",
       "      <td>243.438632</td>\n",
       "      <td>13.202410</td>\n",
       "      <td>5193.692136</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079978</td>\n",
       "      <td>0.110440</td>\n",
       "      <td>2893.187710</td>\n",
       "      <td>0.100018</td>\n",
       "      <td>0.100021</td>\n",
       "      <td>0.100019</td>\n",
       "      <td>1732.667639</td>\n",
       "      <td>3587.297099</td>\n",
       "      <td>11389.679934</td>\n",
       "      <td>0.100016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>8000.120016</td>\n",
       "      <td>59313.700731</td>\n",
       "      <td>86051.223148</td>\n",
       "      <td>42.645277</td>\n",
       "      <td>0.100015</td>\n",
       "      <td>5.163783</td>\n",
       "      <td>1415.506107</td>\n",
       "      <td>264.452796</td>\n",
       "      <td>0.100021</td>\n",
       "      <td>74.800024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133240</td>\n",
       "      <td>0.108810</td>\n",
       "      <td>319.247714</td>\n",
       "      <td>0.100019</td>\n",
       "      <td>398.722536</td>\n",
       "      <td>44.485155</td>\n",
       "      <td>12.834929</td>\n",
       "      <td>47.341063</td>\n",
       "      <td>4887.889734</td>\n",
       "      <td>0.100016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic5</th>\n",
       "      <td>8114.172843</td>\n",
       "      <td>251.543519</td>\n",
       "      <td>0.100018</td>\n",
       "      <td>1352.349310</td>\n",
       "      <td>0.100018</td>\n",
       "      <td>78124.674068</td>\n",
       "      <td>2856.892611</td>\n",
       "      <td>42149.828511</td>\n",
       "      <td>0.100021</td>\n",
       "      <td>249.106843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100558</td>\n",
       "      <td>15.111134</td>\n",
       "      <td>180.589356</td>\n",
       "      <td>0.100019</td>\n",
       "      <td>1.125788</td>\n",
       "      <td>0.179454</td>\n",
       "      <td>6.601214</td>\n",
       "      <td>72.116352</td>\n",
       "      <td>4703.670986</td>\n",
       "      <td>0.100015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic6</th>\n",
       "      <td>3018.957502</td>\n",
       "      <td>0.103600</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>55.889715</td>\n",
       "      <td>0.100014</td>\n",
       "      <td>0.100016</td>\n",
       "      <td>114.682931</td>\n",
       "      <td>65.912295</td>\n",
       "      <td>0.100020</td>\n",
       "      <td>5.568021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100019</td>\n",
       "      <td>0.100019</td>\n",
       "      <td>59326.013907</td>\n",
       "      <td>0.100017</td>\n",
       "      <td>0.100017</td>\n",
       "      <td>0.100016</td>\n",
       "      <td>62510.298520</td>\n",
       "      <td>59660.653014</td>\n",
       "      <td>101.808016</td>\n",
       "      <td>0.100012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic7</th>\n",
       "      <td>22142.931607</td>\n",
       "      <td>105.851756</td>\n",
       "      <td>0.100016</td>\n",
       "      <td>123.407842</td>\n",
       "      <td>0.100017</td>\n",
       "      <td>0.100022</td>\n",
       "      <td>24083.968230</td>\n",
       "      <td>922.121789</td>\n",
       "      <td>107841.207210</td>\n",
       "      <td>1251.643189</td>\n",
       "      <td>...</td>\n",
       "      <td>22.927837</td>\n",
       "      <td>0.115184</td>\n",
       "      <td>1117.022938</td>\n",
       "      <td>0.139208</td>\n",
       "      <td>0.100026</td>\n",
       "      <td>0.100021</td>\n",
       "      <td>124.109183</td>\n",
       "      <td>497.924494</td>\n",
       "      <td>8769.992107</td>\n",
       "      <td>0.100015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4   \\\n",
       "Topic0    154.187145      1.510541      0.100016     11.215323      0.100017   \n",
       "Topic1  10224.871870    983.917846      0.100010    822.665069      0.100016   \n",
       "Topic2     61.804112      0.424129      0.100013  35211.559621  60797.470774   \n",
       "Topic3  15359.187962   6783.401664      0.100014    726.276421      0.100015   \n",
       "Topic4   8000.120016  59313.700731  86051.223148     42.645277      0.100015   \n",
       "Topic5   8114.172843    251.543519      0.100018   1352.349310      0.100018   \n",
       "Topic6   3018.957502      0.103600      0.100011     55.889715      0.100014   \n",
       "Topic7  22142.931607    105.851756      0.100016    123.407842      0.100017   \n",
       "\n",
       "                  5             6             7              8             9   \\\n",
       "Topic0      0.100019     19.361503    590.095924       0.100022      5.318551   \n",
       "Topic1      0.100017  37458.633086   5179.528547       0.750411  72425.579740   \n",
       "Topic2      0.100019     10.506632    268.111232       0.100020      0.108266   \n",
       "Topic3      0.100020   7340.134007    243.438632      13.202410   5193.692136   \n",
       "Topic4      5.163783   1415.506107    264.452796       0.100021     74.800024   \n",
       "Topic5  78124.674068   2856.892611  42149.828511       0.100021    249.106843   \n",
       "Topic6      0.100016    114.682931     65.912295       0.100020      5.568021   \n",
       "Topic7      0.100022  24083.968230    922.121789  107841.207210   1251.643189   \n",
       "\n",
       "        ...            36            37            38            39  \\\n",
       "Topic0  ...      3.327713      0.100021     30.095829  66158.557600   \n",
       "Topic1  ...    328.957354      0.100021    367.533959      0.103667   \n",
       "Topic2  ...  56446.297680  41283.548772     20.037134      0.100052   \n",
       "Topic3  ...      2.079978      0.110440   2893.187710      0.100018   \n",
       "Topic4  ...      0.133240      0.108810    319.247714      0.100019   \n",
       "Topic5  ...      0.100558     15.111134    180.589356      0.100019   \n",
       "Topic6  ...      0.100019      0.100019  59326.013907      0.100017   \n",
       "Topic7  ...     22.927837      0.115184   1117.022938      0.139208   \n",
       "\n",
       "                  40            41            42            43            44  \\\n",
       "Topic0  40855.950700      0.449685      2.557207      0.228810  15159.559355   \n",
       "Topic1      0.100020      0.100019     30.563796    314.032476  29058.007533   \n",
       "Topic2      0.100020  80919.916001      0.104183      0.289335   1906.759769   \n",
       "Topic3      0.100021      0.100019   1732.667639   3587.297099  11389.679934   \n",
       "Topic4    398.722536     44.485155     12.834929     47.341063   4887.889734   \n",
       "Topic5      1.125788      0.179454      6.601214     72.116352   4703.670986   \n",
       "Topic6      0.100017      0.100016  62510.298520  59660.653014    101.808016   \n",
       "Topic7      0.100026      0.100021    124.109183    497.924494   8769.992107   \n",
       "\n",
       "                  45  \n",
       "Topic0  69071.072458  \n",
       "Topic1      0.100014  \n",
       "Topic2      0.100016  \n",
       "Topic3      0.100016  \n",
       "Topic4      0.100016  \n",
       "Topic5      0.100015  \n",
       "Topic6      0.100012  \n",
       "Topic7      0.100015  \n",
       "\n",
       "[8 rows x 46 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_topics(vectorizer, lda_model, n_words=20):\n",
    "    keywords = np.array(vectorizer.get_feature_names_out())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords\n",
    "\n",
    "\n",
    "topic_keywords = show_topics(vectorizer=cv, lda_model=model, n_words=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Word 10</th>\n",
       "      <th>Word 11</th>\n",
       "      <th>Word 12</th>\n",
       "      <th>Word 13</th>\n",
       "      <th>Word 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>gör</td>\n",
       "      <td>år</td>\n",
       "      <td>tid</td>\n",
       "      <td>två</td>\n",
       "      <td>även</td>\n",
       "      <td>fick</td>\n",
       "      <td>finn</td>\n",
       "      <td>fått</td>\n",
       "      <td>måst</td>\n",
       "      <td>eftersom</td>\n",
       "      <td>får</td>\n",
       "      <td>fråg</td>\n",
       "      <td>svar</td>\n",
       "      <td>möj</td>\n",
       "      <td>alltså</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>gäll</td>\n",
       "      <td>fall</td>\n",
       "      <td>lag</td>\n",
       "      <td>kräv</td>\n",
       "      <td>finn</td>\n",
       "      <td>kunn</td>\n",
       "      <td>dock</td>\n",
       "      <td>måst</td>\n",
       "      <td>även</td>\n",
       "      <td>innebär</td>\n",
       "      <td>alltså</td>\n",
       "      <td>eftersom</td>\n",
       "      <td>möj</td>\n",
       "      <td>fråg</td>\n",
       "      <td>andr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>vill</td>\n",
       "      <td>betal</td>\n",
       "      <td>säg</td>\n",
       "      <td>ta</td>\n",
       "      <td>behöv</td>\n",
       "      <td>fått</td>\n",
       "      <td>måst</td>\n",
       "      <td>fick</td>\n",
       "      <td>får</td>\n",
       "      <td>även</td>\n",
       "      <td>svar</td>\n",
       "      <td>eftersom</td>\n",
       "      <td>finn</td>\n",
       "      <td>gör</td>\n",
       "      <td>få</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>kap</td>\n",
       "      <td>person</td>\n",
       "      <td>se</td>\n",
       "      <td>finn</td>\n",
       "      <td>innebär</td>\n",
       "      <td>alltså</td>\n",
       "      <td>även</td>\n",
       "      <td>genom</td>\n",
       "      <td>dock</td>\n",
       "      <td>andr</td>\n",
       "      <td>fall</td>\n",
       "      <td>måst</td>\n",
       "      <td>får</td>\n",
       "      <td>fråg</td>\n",
       "      <td>vänd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>får</td>\n",
       "      <td>barn</td>\n",
       "      <td>andr</td>\n",
       "      <td>först</td>\n",
       "      <td>går</td>\n",
       "      <td>finn</td>\n",
       "      <td>alltså</td>\n",
       "      <td>även</td>\n",
       "      <td>innebär</td>\n",
       "      <td>dock</td>\n",
       "      <td>fråg</td>\n",
       "      <td>fått</td>\n",
       "      <td>svar</td>\n",
       "      <td>två</td>\n",
       "      <td>tack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 5</th>\n",
       "      <td>komm</td>\n",
       "      <td>få</td>\n",
       "      <td>del</td>\n",
       "      <td>eftersom</td>\n",
       "      <td>finn</td>\n",
       "      <td>innebär</td>\n",
       "      <td>alltså</td>\n",
       "      <td>även</td>\n",
       "      <td>dock</td>\n",
       "      <td>fått</td>\n",
       "      <td>möj</td>\n",
       "      <td>behöv</td>\n",
       "      <td>svar</td>\n",
       "      <td>fråg</td>\n",
       "      <td>genom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 6</th>\n",
       "      <td>fråg</td>\n",
       "      <td>svar</td>\n",
       "      <td>vän</td>\n",
       "      <td>vänd</td>\n",
       "      <td>tack</td>\n",
       "      <td>lawlin</td>\n",
       "      <td>hälsning</td>\n",
       "      <td>hopp</td>\n",
       "      <td>fick</td>\n",
       "      <td>fått</td>\n",
       "      <td>alltså</td>\n",
       "      <td>finn</td>\n",
       "      <td>innebär</td>\n",
       "      <td>dock</td>\n",
       "      <td>även</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 7</th>\n",
       "      <td>rätt</td>\n",
       "      <td>enl</td>\n",
       "      <td>genom</td>\n",
       "      <td>möj</td>\n",
       "      <td>dock</td>\n",
       "      <td>alltså</td>\n",
       "      <td>innebär</td>\n",
       "      <td>även</td>\n",
       "      <td>finn</td>\n",
       "      <td>se</td>\n",
       "      <td>får</td>\n",
       "      <td>fall</td>\n",
       "      <td>tack</td>\n",
       "      <td>eftersom</td>\n",
       "      <td>fråg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word 0  Word 1 Word 2    Word 3   Word 4   Word 5    Word 6 Word 7  \\\n",
       "Topic 0    gör      år    tid       två     även     fick      finn   fått   \n",
       "Topic 1   gäll    fall    lag      kräv     finn     kunn      dock   måst   \n",
       "Topic 2   vill   betal    säg        ta    behöv     fått      måst   fick   \n",
       "Topic 3    kap  person     se      finn  innebär   alltså      även  genom   \n",
       "Topic 4    får    barn   andr     först      går     finn    alltså   även   \n",
       "Topic 5   komm      få    del  eftersom     finn  innebär    alltså   även   \n",
       "Topic 6   fråg    svar    vän      vänd     tack   lawlin  hälsning   hopp   \n",
       "Topic 7   rätt     enl  genom       möj     dock   alltså   innebär   även   \n",
       "\n",
       "          Word 8    Word 9 Word 10   Word 11  Word 12   Word 13 Word 14  \n",
       "Topic 0     måst  eftersom     får      fråg     svar       möj  alltså  \n",
       "Topic 1     även   innebär  alltså  eftersom      möj      fråg    andr  \n",
       "Topic 2      får      även    svar  eftersom     finn       gör      få  \n",
       "Topic 3     dock      andr    fall      måst      får      fråg    vänd  \n",
       "Topic 4  innebär      dock    fråg      fått     svar       två    tack  \n",
       "Topic 5     dock      fått     möj     behöv     svar      fråg   genom  \n",
       "Topic 6     fick      fått  alltså      finn  innebär      dock    även  \n",
       "Topic 7     finn        se     får      fall     tack  eftersom    fråg  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = [\n",
    "    \"Word \" + str(i) for i in range(df_topic_keywords.shape[1])\n",
    "]\n",
    "df_topic_keywords.index = [\"Topic \" + str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('capstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "276a14dae6666bcb6ed89d918896adede68a2b9bdb45438fbd6182b59f67b49f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
