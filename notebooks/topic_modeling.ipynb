{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling notebook\n",
    "\n",
    "This notebook details the steps taken to clean the data and run topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SwedishStemmer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\"../dataset/lawline_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make new column with lowercase texts and remove all whitespace plus tabs/newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only questions/answers\n",
    "df = df_full.iloc[::2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_34608\\2512645272.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_clean\"] = df[\"text\"].str.lower()\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_34608\\2512645272.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_clean\"] = [\" \".join(str(item).split()) for item in df[\"text_clean\"]]\n"
     ]
    }
   ],
   "source": [
    "df[\"text_clean\"] = df[\"text\"].str.lower()\n",
    "df[\"text_clean\"] = [\" \".join(str(item).split()) for item in df[\"text_clean\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_34608\\1299325099.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"text_clean\"] = df[\"text_clean\"].str.replace(\"[^\\w\\s]\", \"\")\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_34608\\1299325099.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_clean\"] = df[\"text_clean\"].str.replace(\"[^\\w\\s]\", \"\")\n"
     ]
    }
   ],
   "source": [
    "df[\"text_clean\"] = df[\"text_clean\"].str.replace(\"[^\\w\\s]\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove numbers and replace more than one whitespace with single whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_34608\\147325655.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"text_clean\"] = df[\"text_clean\"].str.replace(\"[0-9]\", \"\")\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_34608\\147325655.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_clean\"] = df[\"text_clean\"].str.replace(\"[0-9]\", \"\")\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_34608\\147325655.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[\"text_clean\"] = df[\"text_clean\"].str.replace(\"\\s{2,}\", \" \")\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_34608\\147325655.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_clean\"] = df[\"text_clean\"].str.replace(\"\\s{2,}\", \" \")\n"
     ]
    }
   ],
   "source": [
    "df[\"text_clean\"] = df[\"text_clean\"].str.replace(\"[0-9]\", \"\")\n",
    "df[\"text_clean\"] = df[\"text_clean\"].str.replace(\"\\s{2,}\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords function\n",
    "def remove_stopwords(texts, stop_words):\n",
    "    return [\n",
    "        [word for word in simple_preprocess(str(doc)) if word not in stop_words]\n",
    "        for doc in texts\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn texts to list of words and remove stop words. Then turn texts to term document frequency corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn texts to list\n",
    "list_texts = df[\"text_clean\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"swedish\")\n",
    "stop_words.extend([\n",
    "    \"hej\", \"ska\", \"in\", \"vill\", \"alltså\", \"lawline\", \"även\",\n",
    "    \"kommer\", \"fråga\", \"finns\"\n",
    "    ])\n",
    "\n",
    "text_words = remove_stopwords(list_texts, stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stem words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SwedishStemmer()\n",
    "\n",
    "text_stemmed = [[stemmer.stem(word) for word in doc] for doc in text_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_stemmed = [\" \".join(doc) for doc in text_stemmed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=0.2, max_df=0.8,\n",
    "                     stop_words=stopwords.words(\"swedish\"))\n",
    "\n",
    "trunc_texts = cv.fit_transform(docs_stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train LDA model on corpus with differing number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 33 candidates, totalling 165 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LatentDirichletAllocation(learning_method=&#x27;online&#x27;,\n",
       "                                                 random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_decay&#x27;: [0.5, 0.7, 1],\n",
       "                         &#x27;n_components&#x27;: [3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 20]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LatentDirichletAllocation(learning_method=&#x27;online&#x27;,\n",
       "                                                 random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_decay&#x27;: [0.5, 0.7, 1],\n",
       "                         &#x27;n_components&#x27;: [3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 20]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(learning_method=&#x27;online&#x27;, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(learning_method=&#x27;online&#x27;, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LatentDirichletAllocation(learning_method='online',\n",
       "                                                 random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_decay': [0.5, 0.7, 1],\n",
       "                         'n_components': [3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 20]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First take Grid Search approach\n",
    "grid = {\n",
    "    #'doc_topic_prior': [.05, .1, .5, 1, 5, 10],\n",
    "    #'topic_word_prior': [.05, .1, .5, 1, 5, 10],\n",
    "    \"n_components\": [3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 20],\n",
    "    'learning_decay': [.5, .7, 1]\n",
    "}\n",
    "\n",
    "mod = LDA(\n",
    "    max_iter=10,\n",
    "    learning_method=\"online\",\n",
    "    random_state=42,\n",
    "    batch_size=128,\n",
    "    evaluate_every=-1,\n",
    ")\n",
    "\n",
    "# clf = RandomizedSearchCV(mod, param_distributions=grid, n_jobs=-1,\n",
    "#                          n_iter=10, verbose=1)\n",
    "\n",
    "clf = GridSearchCV(mod, param_grid=grid, n_jobs=-1, verbose=1)\n",
    "\n",
    "clf.fit(trunc_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\samue\\Documents\\GitHub\\capstone_22\\notebooks\\topic_modeling.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000020?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m num_topic \u001b[39min\u001b[39;00m num_topics:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000020?line=4'>5</a>\u001b[0m     mod \u001b[39m=\u001b[39m LDA(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000020?line=5'>6</a>\u001b[0m     n_components\u001b[39m=\u001b[39mnum_topic,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000020?line=6'>7</a>\u001b[0m     max_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000020?line=11'>12</a>\u001b[0m     n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000020?line=12'>13</a>\u001b[0m     )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000020?line=14'>15</a>\u001b[0m     mod\u001b[39m.\u001b[39;49mfit(trunc_texts)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/samue/Documents/GitHub/capstone_22/notebooks/topic_modeling.ipynb#ch0000020?line=16'>17</a>\u001b[0m     lda_list\u001b[39m.\u001b[39mappend(mod)\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:632\u001b[0m, in \u001b[0;36mLatentDirichletAllocation.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m learning_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39monline\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    631\u001b[0m     \u001b[39mfor\u001b[39;00m idx_slice \u001b[39min\u001b[39;00m gen_batches(n_samples, batch_size):\n\u001b[1;32m--> 632\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_em_step(\n\u001b[0;32m    633\u001b[0m             X[idx_slice, :],\n\u001b[0;32m    634\u001b[0m             total_samples\u001b[39m=\u001b[39;49mn_samples,\n\u001b[0;32m    635\u001b[0m             batch_update\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    636\u001b[0m             parallel\u001b[39m=\u001b[39;49mparallel,\n\u001b[0;32m    637\u001b[0m         )\n\u001b[0;32m    638\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     \u001b[39m# batch update\u001b[39;00m\n\u001b[0;32m    640\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_em_step(\n\u001b[0;32m    641\u001b[0m         X, total_samples\u001b[39m=\u001b[39mn_samples, batch_update\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, parallel\u001b[39m=\u001b[39mparallel\n\u001b[0;32m    642\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:503\u001b[0m, in \u001b[0;36mLatentDirichletAllocation._em_step\u001b[1;34m(self, X, total_samples, batch_update, parallel)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[39m\"\"\"EM update for 1 iteration.\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \n\u001b[0;32m    478\u001b[0m \u001b[39mupdate `_component` by batch VB or online VB.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[39m    Unnormalized document topic distribution.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[39m# E-step\u001b[39;00m\n\u001b[1;32m--> 503\u001b[0m _, suff_stats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_e_step(\n\u001b[0;32m    504\u001b[0m     X, cal_sstats\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, random_init\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, parallel\u001b[39m=\u001b[39;49mparallel\n\u001b[0;32m    505\u001b[0m )\n\u001b[0;32m    507\u001b[0m \u001b[39m# M-step\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[39mif\u001b[39;00m batch_update:\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:446\u001b[0m, in \u001b[0;36mLatentDirichletAllocation._e_step\u001b[1;34m(self, X, cal_sstats, random_init, parallel)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[39mif\u001b[39;00m parallel \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[1;32m--> 446\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    447\u001b[0m     delayed(_update_doc_distribution)(\n\u001b[0;32m    448\u001b[0m         X[idx_slice, :],\n\u001b[0;32m    449\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexp_dirichlet_component_,\n\u001b[0;32m    450\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdoc_topic_prior_,\n\u001b[0;32m    451\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_doc_update_iter,\n\u001b[0;32m    452\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean_change_tol,\n\u001b[0;32m    453\u001b[0m         cal_sstats,\n\u001b[0;32m    454\u001b[0m         random_state,\n\u001b[0;32m    455\u001b[0m     )\n\u001b[0;32m    456\u001b[0m     \u001b[39mfor\u001b[39;49;00m idx_slice \u001b[39min\u001b[39;49;00m gen_even_slices(X\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], n_jobs)\n\u001b[0;32m    457\u001b[0m )\n\u001b[0;32m    459\u001b[0m \u001b[39m# merge result\u001b[39;00m\n\u001b[0;32m    460\u001b[0m doc_topics, sstats_list \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mresults)\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\concurrent\\futures\\_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 440\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    443\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\samue\\miniconda3\\envs\\capstone\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lda_list = []\n",
    "num_topics = [3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 20]\n",
    "\n",
    "for num_topic in num_topics:\n",
    "    mod = LDA(\n",
    "        n_components=num_topic,\n",
    "        max_iter=10,\n",
    "        learning_method=\"online\",\n",
    "        random_state=42,\n",
    "        batch_size=128,\n",
    "        evaluate_every=-1,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    mod.fit(trunc_texts)\n",
    "\n",
    "    lda_list.append(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perp_list = [mod.perplexity(trunc_texts) for mod in lda_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lda_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53279297, 0.22178771, 0.24541932],\n",
       "       [0.32000544, 0.31194701, 0.36804755],\n",
       "       [0.09642113, 0.64713961, 0.25643926],\n",
       "       ...,\n",
       "       [0.22011287, 0.71418488, 0.06570225],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.1666755 , 0.66656293, 0.16676158]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_transform(trunc_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicnames = [\"Topic\" + str(i) for i in range(model.n_components)]\n",
    "df_topic_keywords = pd.DataFrame(model.components_)\n",
    "df_topic_keywords.index = topicnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic0</th>\n",
       "      <td>3221.641275</td>\n",
       "      <td>13.900550</td>\n",
       "      <td>252.072197</td>\n",
       "      <td>4561.217738</td>\n",
       "      <td>0.689225</td>\n",
       "      <td>2313.429881</td>\n",
       "      <td>7755.278838</td>\n",
       "      <td>50925.194520</td>\n",
       "      <td>22438.780692</td>\n",
       "      <td>0.503091</td>\n",
       "      <td>...</td>\n",
       "      <td>12138.675401</td>\n",
       "      <td>0.372382</td>\n",
       "      <td>149.696333</td>\n",
       "      <td>5574.545398</td>\n",
       "      <td>13910.776112</td>\n",
       "      <td>943.564910</td>\n",
       "      <td>38311.523138</td>\n",
       "      <td>0.390434</td>\n",
       "      <td>514.747026</td>\n",
       "      <td>35790.979774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>31520.905197</td>\n",
       "      <td>46902.174793</td>\n",
       "      <td>37671.072798</td>\n",
       "      <td>20616.913519</td>\n",
       "      <td>59121.459016</td>\n",
       "      <td>44313.344518</td>\n",
       "      <td>1192.785688</td>\n",
       "      <td>3322.214359</td>\n",
       "      <td>27226.062268</td>\n",
       "      <td>6.978639</td>\n",
       "      <td>...</td>\n",
       "      <td>16199.395535</td>\n",
       "      <td>0.377844</td>\n",
       "      <td>83087.187066</td>\n",
       "      <td>13733.858202</td>\n",
       "      <td>15621.449898</td>\n",
       "      <td>18898.726067</td>\n",
       "      <td>33.306020</td>\n",
       "      <td>0.427644</td>\n",
       "      <td>24638.608282</td>\n",
       "      <td>0.365689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>7122.242666</td>\n",
       "      <td>0.387045</td>\n",
       "      <td>5205.421969</td>\n",
       "      <td>7255.800658</td>\n",
       "      <td>0.605760</td>\n",
       "      <td>1160.768565</td>\n",
       "      <td>12867.949549</td>\n",
       "      <td>81.000347</td>\n",
       "      <td>10877.195454</td>\n",
       "      <td>28156.206564</td>\n",
       "      <td>...</td>\n",
       "      <td>84.356646</td>\n",
       "      <td>44424.899357</td>\n",
       "      <td>1.401618</td>\n",
       "      <td>33332.165140</td>\n",
       "      <td>2621.400201</td>\n",
       "      <td>26354.500437</td>\n",
       "      <td>0.372112</td>\n",
       "      <td>32224.182522</td>\n",
       "      <td>28034.024374</td>\n",
       "      <td>0.365734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4   \\\n",
       "Topic0   3221.641275     13.900550    252.072197   4561.217738      0.689225   \n",
       "Topic1  31520.905197  46902.174793  37671.072798  20616.913519  59121.459016   \n",
       "Topic2   7122.242666      0.387045   5205.421969   7255.800658      0.605760   \n",
       "\n",
       "                  5             6             7             8             9   \\\n",
       "Topic0   2313.429881   7755.278838  50925.194520  22438.780692      0.503091   \n",
       "Topic1  44313.344518   1192.785688   3322.214359  27226.062268      6.978639   \n",
       "Topic2   1160.768565  12867.949549     81.000347  10877.195454  28156.206564   \n",
       "\n",
       "        ...            20            21            22            23  \\\n",
       "Topic0  ...  12138.675401      0.372382    149.696333   5574.545398   \n",
       "Topic1  ...  16199.395535      0.377844  83087.187066  13733.858202   \n",
       "Topic2  ...     84.356646  44424.899357      1.401618  33332.165140   \n",
       "\n",
       "                  24            25            26            27            28  \\\n",
       "Topic0  13910.776112    943.564910  38311.523138      0.390434    514.747026   \n",
       "Topic1  15621.449898  18898.726067     33.306020      0.427644  24638.608282   \n",
       "Topic2   2621.400201  26354.500437      0.372112  32224.182522  28034.024374   \n",
       "\n",
       "                  29  \n",
       "Topic0  35790.979774  \n",
       "Topic1      0.365689  \n",
       "Topic2      0.365734  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_topics(vectorizer, lda_model, n_words=20):\n",
    "    keywords = np.array(vectorizer.get_feature_names_out())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords\n",
    "\n",
    "\n",
    "topic_keywords = show_topics(vectorizer=cv, lda_model=model, n_words=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Word 10</th>\n",
       "      <th>Word 11</th>\n",
       "      <th>Word 12</th>\n",
       "      <th>Word 13</th>\n",
       "      <th>Word 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>få</td>\n",
       "      <td>tid</td>\n",
       "      <td>gör</td>\n",
       "      <td>år</td>\n",
       "      <td>får</td>\n",
       "      <td>måst</td>\n",
       "      <td>säg</td>\n",
       "      <td>möj</td>\n",
       "      <td>fick</td>\n",
       "      <td>svar</td>\n",
       "      <td>eftersom</td>\n",
       "      <td>kräv</td>\n",
       "      <td>andr</td>\n",
       "      <td>fall</td>\n",
       "      <td>tack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>kap</td>\n",
       "      <td>rätt</td>\n",
       "      <td>enl</td>\n",
       "      <td>gäll</td>\n",
       "      <td>del</td>\n",
       "      <td>fall</td>\n",
       "      <td>innebär</td>\n",
       "      <td>lag</td>\n",
       "      <td>dock</td>\n",
       "      <td>genom</td>\n",
       "      <td>andr</td>\n",
       "      <td>kräv</td>\n",
       "      <td>får</td>\n",
       "      <td>vänd</td>\n",
       "      <td>måst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>person</td>\n",
       "      <td>svar</td>\n",
       "      <td>vän</td>\n",
       "      <td>hälsning</td>\n",
       "      <td>fått</td>\n",
       "      <td>vänd</td>\n",
       "      <td>tack</td>\n",
       "      <td>gör</td>\n",
       "      <td>hopp</td>\n",
       "      <td>fick</td>\n",
       "      <td>får</td>\n",
       "      <td>eftersom</td>\n",
       "      <td>andr</td>\n",
       "      <td>dock</td>\n",
       "      <td>säg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word 0 Word 1 Word 2    Word 3 Word 4 Word 5   Word 6 Word 7 Word 8  \\\n",
       "Topic 0      få    tid    gör        år    får   måst      säg    möj   fick   \n",
       "Topic 1     kap   rätt    enl      gäll    del   fall  innebär    lag   dock   \n",
       "Topic 2  person   svar    vän  hälsning   fått   vänd     tack    gör   hopp   \n",
       "\n",
       "        Word 9   Word 10   Word 11 Word 12 Word 13 Word 14  \n",
       "Topic 0   svar  eftersom      kräv    andr    fall    tack  \n",
       "Topic 1  genom      andr      kräv     får    vänd    måst  \n",
       "Topic 2   fick       får  eftersom    andr    dock     säg  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = [\n",
    "    \"Word \" + str(i) for i in range(df_topic_keywords.shape[1])\n",
    "]\n",
    "df_topic_keywords.index = [\"Topic \" + str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('capstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "276a14dae6666bcb6ed89d918896adede68a2b9bdb45438fbd6182b59f67b49f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
